<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Bryan Schafroth Portfolio</title>
    <link>/categories/machine-learning/</link>
    <description>Recent content in Machine Learning on Bryan Schafroth Portfolio</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 01 Jul 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Reinforcement Learning Problem</title>
      <link>/post/2018/07/01/reinforcement-learing-problem/</link>
      <pubDate>Sun, 01 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/07/01/reinforcement-learing-problem/</guid>
      <description>Reinforcement Learning - Grid World ProblemThe first section looks at the grid world concept/problem. The environment is a 3x4 grid and the goal is to move from the start xy (1,1) (called a “state”&#34;) location to the opposite corner (4,3) called the goal state. The actions are up, down, left, right. We have the rewards of +1 &amp;amp; -1. We want the agent to find the shortest sequence of actions to get from start to end (goal).</description>
    </item>
    
    <item>
      <title>K-Means - Hierarchial Cluster Analysis</title>
      <link>/post/2018/06/17/k-means-hierarchial-cluster-analysis/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/06/17/k-means-hierarchial-cluster-analysis/</guid>
      <description>K-Means AnalysisThis project will use the Wholesale customer Data Set from: https://archive.ics.uci.edu/ml/datasets/Wholesale+customers. The data has 440 orbs and 8 variables. The data has the Channel and Region as integers but they are categorical in nature with 2 channels and 3 regions. We think this may need to be taken out of the analysis but will leave them in for now. A general observation about the variables there are outliers in the 6 major variables: fresh, milk, grocery, frozen, detergents_paper, delicassen.</description>
    </item>
    
    <item>
      <title>Artificial Neural Network and Support Vector Machine Analysis</title>
      <link>/post/2018/06/10/artificial-neural-network-and-support-vector-machine-analysis/</link>
      <pubDate>Sun, 10 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/06/10/artificial-neural-network-and-support-vector-machine-analysis/</guid>
      <description>IntroductionThe data set is the mushroom set retrieved from: http://archive.ics.uci.edu/ml/datasets/Mushroom. It consists of 8124 orbs and 23 variables. The classification variable is the “type” either edible (e) or poisonous (p). The remaining 22 variables are the predictors and consist of multiple levels from 1 to 12 each. The data columns will need to be named and are coded in short for each. There are 2480 NA’s found and in one variable “sr” or stalk root.</description>
    </item>
    
    <item>
      <title>K-Nearest Neighbor (KNN) - Heart Disease Dataset</title>
      <link>/post/2018/05/20/k-nearest-neighbor-knn-heart-disease-dataset/</link>
      <pubDate>Sun, 20 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/05/20/k-nearest-neighbor-knn-heart-disease-dataset/</guid>
      <description>Introduction to K-Nearest NeighborKNN is a supervised learning algorithm and uses a training sample from the dataset, which classifies groups into different classes. It is a classifier used to predict the level of an unknown point (observation) and does this by measuring the points nearest to the unknown point. It works well in measuring the differences between multiple classes that are complex and hard to detect. KNN is considered a simple classification and regression algorithm.</description>
    </item>
    
  </channel>
</rss>