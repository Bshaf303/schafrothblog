<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on Bryan Schafroth Portfolio</title>
    <link>/</link>
    <description>Recent content in Home on Bryan Schafroth Portfolio</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 09 Mar 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Open Data – Annual Crime Dataset 2015</title>
      <link>/post/2019/03/09/open-data-annual-crime-dataset-2015/</link>
      <pubDate>Sat, 09 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/03/09/open-data-annual-crime-dataset-2015/</guid>
      <description>Data.gov has a “Local Government” (data.gov, 2019b) section among fourteen available topics to obtain data. In the “All Local Government section, as of this writing, there are 17,209 datasets (data.gov, 2019a). Filtering found in the “Organizations” or “Publishers” tab will isolate all the data available for Austin, Texas. Not all U.S. States, cities, and counties are in this resource, which does not indicate the data are not available. A direct way to find local data is to go to the city, state, or county websites.</description>
    </item>
    
    <item>
      <title>Using Data.gov and Applications that Solve Problems</title>
      <link>/post/2019/03/04/using-data-gov-and-applications-that-solve-problems/</link>
      <pubDate>Mon, 04 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/03/04/using-data-gov-and-applications-that-solve-problems/</guid>
      <description>On the data.gov application site, there are a handful of examples where the open data from data.gov can provide a service to consumers. There is a good sampling of applications voluntarily submitted to the site for the chance to be featured. Data.gov does not say they endorse the applications.
 One of the many applications is Redfin. I recently learned about Redfin on television, and it was a commercial for the company.</description>
    </item>
    
    <item>
      <title>Data Science for Social Justice - Bolivia Case Study</title>
      <link>/post/2019/03/02/data-science-for-social-justice-bolivia-case-study/</link>
      <pubDate>Sat, 02 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/03/02/data-science-for-social-justice-bolivia-case-study/</guid>
      <description>Data science for social justice is a present-day concept that is gaining more recognition and popularity in the world. Solving current social problems using available open-source data and data science skillsets will help many world populations and is an ongoing challenge. The article reviews an old case study about Cochabamba, Bolivia’s problem with water infrastructure privatization, and what happened in the year 2000. While the data science profession, open data sources, and current technologies were not around in 2000, this article is a speculative assessment on how a data scientist from two sides may retrospectively go about the work today given the skills and technologies available.</description>
    </item>
    
    <item>
      <title>Social Justice Aided with Data Science</title>
      <link>/post/2019/02/25/social-justice-aided-with-data-science/</link>
      <pubDate>Mon, 25 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/02/25/social-justice-aided-with-data-science/</guid>
      <description>The social justice issue that data science can aid with is life expectancy throughout the world. The social justice issue is a project that was brought to the world&amp;rsquo;s attention by Hans Rosling, and you can see his presentation on Youtube in the references. He compared the life expectancy to the Gross Domestic Product per capita (GPD) of the countries, and plotting the data found a strong correlation between GDP and the life span of the Country&amp;rsquo;s citizens.</description>
    </item>
    
    <item>
      <title>Social Media and Social Justice Fast Food Targeting</title>
      <link>/post/2019/02/22/social-media-and-social-justice-fast-food-targeting/</link>
      <pubDate>Fri, 22 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/02/22/social-media-and-social-justice-fast-food-targeting/</guid>
      <description>This article discusses a potential social justice project using social media data. Contained in the article is a description of the social justice issue and presented in a mind map. The paper discusses the purpose of the research and why the project is exploring a potential social justice problem in social media. The analysis then speculates the ethical and privacy issues relating to the project. A final summary and status of the social justice problem conclude this paper.</description>
    </item>
    
    <item>
      <title>Sentiment Analysis and Social Media Use Policy</title>
      <link>/post/2019/02/18/sentiment-analysis-and-social-media-use-policy/</link>
      <pubDate>Mon, 18 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/02/18/sentiment-analysis-and-social-media-use-policy/</guid>
      <description>The data scientist should read all agreements and policies of the specific social media site before engaging in data mining for sentiment analysis. The agreements and policies are carefully written by social media companies to protect users, the social company, and the developers. On Twitter&amp;rsquo;s Developers Agreement under &amp;ldquo;VII. Other Important Terms&amp;rdquo; there is a guide on what information is available and how it should not be used (Twitter Developer, May 25, 2018).</description>
    </item>
    
    <item>
      <title>Government Data Planning - U.S. Compared to Australia</title>
      <link>/post/2019/02/16/government-data-planning-u-s-compared-to-australia/</link>
      <pubDate>Sat, 16 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/02/16/government-data-planning-u-s-compared-to-australia/</guid>
      <description>New South Wales (NSW), Australia is one of six states, and each state has a government structure similar to the Commonwealth or Federal branch (Australian government, n.d.). NSW has web resources available that include information on all government services. The site is a one-stop place to find government services related to policy, digital services, and user tools (NSW Government, 2019a). A section of the NSW website, under the &amp;ldquo;policy,&amp;rdquo; is the Data and Information services discussed in this paper.</description>
    </item>
    
    <item>
      <title>Body-Worn Camera&#39;s &amp; Privacy in Law Enforcement</title>
      <link>/post/2019/02/13/body-worn-camera-s-privacy-in-law-enforcement/</link>
      <pubDate>Wed, 13 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/02/13/body-worn-camera-s-privacy-in-law-enforcement/</guid>
      <description>This presentation explores the Bureau of Justice Statistics and discusses privacy issues that are related to data obtained from Law Enforcement Agencies use of body-worn camera’s. Direct Link to slides:Body-Worn Cameras Slide Presentation
Or hover mouse over slide and scroll through:
</description>
    </item>
    
    <item>
      <title>State, Local, Federal Data Social Media Sources</title>
      <link>/post/2019/02/11/state-local-federal-data-sources/</link>
      <pubDate>Mon, 11 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/02/11/state-local-federal-data-sources/</guid>
      <description>The City and County of Denver have a social media policy, and the council does encourage social media usage; however, it must be in line with the local government&amp;rsquo;s mission (City and County of Denver, n.d.). The policy states the social media is not an official government communication and does not guarantee information accuracy and completeness (City and County of Denver, n.d). The social media provided on external sites is a public service; thus, mining data is acceptable.</description>
    </item>
    
    <item>
      <title>Government Regulations Slide Presentation</title>
      <link>/post/2019/02/07/government-regulations-slide-presentation/</link>
      <pubDate>Thu, 07 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/02/07/government-regulations-slide-presentation/</guid>
      <description>This article is a slide presentation discussing government regulations covering the legal aspects of privacy. It covers the industry regulated why it was created and other interesting information. A direct link to the slide presentation can be found here: Government Regulations Slide Presentation
Or hover mouse over slide and scroll through:
</description>
    </item>
    
    <item>
      <title>Algorithm Bias in Analysis</title>
      <link>/post/2019/02/03/agorithm-bias-in-analysis/</link>
      <pubDate>Sun, 03 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/02/03/agorithm-bias-in-analysis/</guid>
      <description>The term &amp;ldquo;bias&amp;rdquo; concerning an analysis of population data concerning machine learning and predictive analytic algorithms can result in bias, and that would be a bit more in-depth for this discussion. According to Bruce and Bruce (2017), the bias seen in statistical measurement or sampling errors is likely due to the process of measurement and sampling methods. Bias may be observable or invisible and detected by referencing or benchmarking values.</description>
    </item>
    
    <item>
      <title>Employee Ethical Breach</title>
      <link>/post/2019/01/28/employee-ethical-breach/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/01/28/employee-ethical-breach/</guid>
      <description>The article is from August of 2018 and found in the Healthcare IT News, among others. The ethics breach was by a Canadian pharmacist in Nova Scotia. The pharmacist caught accessing the health records of approximately 46 patients that the pharmacist knew (Minion, 2018). The ethics breach was spread over two years until the Canadian Privacy Commission discovered what was happening though standard audits. The article said this pharmacist had looked at the records of former classmates, her doctor, and a person whom she had a car accident with, her kid&amp;rsquo;s therapist, her coworkers, family members, and her kid&amp;rsquo;s girlfriend (Minion, 2018).</description>
    </item>
    
    <item>
      <title>A Case Study on Genome Privacy</title>
      <link>/post/2019/01/27/a-case-study-on-genome-privacy/</link>
      <pubDate>Sun, 27 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/01/27/a-case-study-on-genome-privacy/</guid>
      <description>The premise of this article is Walser-Kuntz, Deel, and Singer&amp;rsquo;s case study in genome privacy (2005). The authors of the case study state that biosciences have been able to isolate the single nucleotide polymorphism (SNP) as part of humans&amp;rsquo; DNA markers (Walser-Kuntz, Deel, &amp;amp; Singer, 2005). The SNPs have three uses, according to Walser-Kuntz, Deel, &amp;amp; Singer: genetic markers for disease, specialized applications in medicine, and mapping human evolution (p.</description>
    </item>
    
    <item>
      <title>Case Study on Data Collection: Harvesting Personalities Online</title>
      <link>/post/2019/01/27/case-study-on-data-collection-harvesting-personalities-online/</link>
      <pubDate>Sun, 27 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/01/27/case-study-on-data-collection-harvesting-personalities-online/</guid>
      <description>Raicu wrote a case study for the Santa Clara University discussing the data analytics firm Cambridge Analytica who provided marketing services for various political campaigns (2016). The case study reveals Cambridge Analytica assumed the personality type of nearly all of the registered voters in the U.S. (Raicu, 2016). The study attempts to answer how Cambridge Analytica determined the personality type of 190 million people who were registered to vote across the U.</description>
    </item>
    
    <item>
      <title>Informed Consent and Data Science</title>
      <link>/post/2019/01/23/informed-consent-and-data-science/</link>
      <pubDate>Wed, 23 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/01/23/informed-consent-and-data-science/</guid>
      <description>This retrospective study is from the Netherlands. See the published research article in the reference section below. The article review uses data from 2000 to 2016 and identifies 2,037 children that were previous patients at a university hospital (Draijer, Bosch, Wiegman, Sjouke, Benninga, &amp;amp; Koot, 2018, p.174). The kids screened for liver disease with the goal of this study to use a higher-performing algorithm that improves the accuracy in detecting the condition.</description>
    </item>
    
    <item>
      <title>Data Science and a Code of Ethics</title>
      <link>/post/2019/01/20/data-science-and-a-code-of-ethics/</link>
      <pubDate>Sun, 20 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/01/20/data-science-and-a-code-of-ethics/</guid>
      <description>The Association for Computing Machinery (ACM) created the ACM Code of Ethics and Professional Conduct to direct computing professionals to act and promote ethical behavior in the profession (ACM, 2018). The ACM Code of Ethics and Professional Conduct is in four sections: General Ethical Principles, Professional Responsibilities, Professional Leadership Principles, and Compliance With the Code (ACM, 2018). This paper will discuss the seven General Ethical Principles and classify them into the three major areas of ethics, privacy, and social justice.</description>
    </item>
    
    <item>
      <title>Ethical Issues a Data Scientist Could Face</title>
      <link>/post/2019/01/15/ethical-issues-a-data-scientist-could-face/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/01/15/ethical-issues-a-data-scientist-could-face/</guid>
      <description>The Association for Computing Machinery (ACM) has a code of ethics and professional conduct guidelines (ACM, 2018). The &amp;ldquo;code&amp;rdquo; is for people that work in computing and a guide to consider when decision making. Section 2.9 outlines the need to design systems that are very secure and recognizing that breaches of computer systems can be malevolent to many people and organizations (ACM, 2018). The ACM states not to roll out systems without thorough testing of security exploits (2018).</description>
    </item>
    
    <item>
      <title>Image Classification - A Computer Vision Problem</title>
      <link>/post/2018/12/16/image-classification-a-computer-vision-problem/</link>
      <pubDate>Sun, 16 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/12/16/image-classification-a-computer-vision-problem/</guid>
      <description>Seedling Image Classification - A Convolutional Neural Network Problem in RStudioTable of ContentsThe Project OriginsImage DataThe Data Science ProblemThe Software to Work the ProblemData ExplorationImage AugmentationBase ModelVGG16 Pretrained ModelTraining and Validation GraphsData Augment – Balance ClassesVGG16 Pretrained Model – Freeze/UnfreezeTraining and Validation GraphsPredictions and Evaluations –VGG16Multi-Class ROC/AUCImproving the model - Part 2Predictions and Evaluations –VGG16Multi-Class ROC/AUCSummaryReferencesFigure 1: Image of invasive weed species growing in a crop.</description>
    </item>
    
    <item>
      <title>Classification Problem using Machine Learning</title>
      <link>/post/2018/10/21/classification-problem-using-machine-learning-forest-cover-type/</link>
      <pubDate>Sun, 21 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/10/21/classification-problem-using-machine-learning-forest-cover-type/</guid>
      <description>IntroductionThis article will present a machine learning problem and the concept behind solving the problem. The project will go into detail about the early exploratory steps and build a machine learning model that can be used in production to categorize data. This project is to categorize seven Rocky Mountain tree types found in the forests. In this project, we will use old legacy data from the 1990s and use modern machine learning methods to categorize the data.</description>
    </item>
    
    <item>
      <title>K-Means Clustering Analysis</title>
      <link>/post/2018/08/12/k-means-clustering-analysis/</link>
      <pubDate>Sun, 12 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/08/12/k-means-clustering-analysis/</guid>
      <description>K-Means ClusteringThe first section uses the iris data set and k-means clustering starting with 3 cluster centers and an nstart of 15. The results are displayed below in the fit object. There are 3 clusters sized 50, 62, and 38. The within sum of squares by cluster is 88.4% and the smaller number (15.15, 39.82, &amp;amp; 23.87) indicates how closely related objects are in the clusters. The first cluster has the most related objects and the second cluster has the lesser of related objects mostly taken from the third cluster.</description>
    </item>
    
    <item>
      <title>Application of K-Means - A Brief Case Study</title>
      <link>/post/2018/08/06/application-of-k-means-a-brief-case-study/</link>
      <pubDate>Mon, 06 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/08/06/application-of-k-means-a-brief-case-study/</guid>
      <description>K-Means Case StudyThis article is an example of practical use for k-means clustering from a case study conducted in a Chinese city. The project comes from the IoT smart city concept and looks at real-time traffic network data and uses the k-means algorithm to analyze real data. The emerging intelligent transportation techniques are helping the urban environment run smoother though very complex. The authors take a small segment and look at supply chain logistics such as for manufacturing (raw materials), utilities (coal), banking (banknotes), and the cost related to the processing and transportation between the center and the supplier points.</description>
    </item>
    
    <item>
      <title>Hierarchical Clustering (HCA)</title>
      <link>/post/2018/08/04/hierarchical-clustering-hca/</link>
      <pubDate>Sat, 04 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/08/04/hierarchical-clustering-hca/</guid>
      <description>Hierarchical ClusteringThe hierarchical agglomerative clustering starts with each observation as a cluster and pairs two at a time until all clusters are merged into one single cluster. The number of clusters is not known or specified in advance. The distance between all pairs of points in the data is recorded. There is a dendrogram (upside down tree structure) that is the output of the grouping of clusters. It represents and shows how many clusters were found in the data.</description>
    </item>
    
    <item>
      <title>R Analysis - Plotting Graphics</title>
      <link>/post/2018/07/29/r-analysis-plotting-graphics/</link>
      <pubDate>Sun, 29 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/07/29/r-analysis-plotting-graphics/</guid>
      <description>R Graphics for Exploring DataThe graphics device prints the graphics to screen or into a file type read by other apps. The screen device is on our computers. For windows its windows(), mac its quartz() and Linux its x11(). I am assuming this is built into the R functions plot(), xyplot(), and qplot() when we use them to plot. The other “devices” are the file types that are created by the device.</description>
    </item>
    
    <item>
      <title>Data Analysis - Exploratory Graphics</title>
      <link>/post/2018/07/22/data-analysis-exploratory-graphics/</link>
      <pubDate>Sun, 22 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/07/22/data-analysis-exploratory-graphics/</guid>
      <description>Exploratory Graphics in RThe focus of this analysis is on the ways to graph data set variables. The first section uses the EPA data set retrieved from: https://github.com/jtleek/modules/blob/master/04_ExploratoryAnalysis/exploratoryGraphs/data/avgpm25.csv the data was imported into a csv file and then used for this first section. Code notes for explaination.
The first part uses the RStudio base functionality to plot graphics then we use maps, lattice, and ggplot2 to compare and contrast.</description>
    </item>
    
    <item>
      <title>Exploratory Data Analysis - EPA Ozone Data</title>
      <link>/post/2018/07/14/exploratory-data-analysis-epa-ozone-data/</link>
      <pubDate>Sat, 14 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/07/14/exploratory-data-analysis-epa-ozone-data/</guid>
      <description>IntroductionThis exploratory data analysis will use the “hourly_44201_2014” data set obtained from the web site: https://aqs.epa.gov/aqsweb/airdata/download_files.html#Raw The data is “Criteria Gases” and labeled “Ozone (44201)” for this particular data set. The data is loaded into RStudio and shows 9,060,694 rows and 24 variables.
There are 24 variables in this data set. Looking through the variables, we can see the first four are coded presumably by the EPA. The Latitude, Longitude, and Datum are geo-location data.</description>
    </item>
    
    <item>
      <title>Data Exploration - The Chicago Dataset</title>
      <link>/post/2018/07/07/data-exploration-the-chicago-dataset/</link>
      <pubDate>Sat, 07 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/07/07/data-exploration-the-chicago-dataset/</guid>
      <description>IntroductionThis article is about using the tidyverse package in R to explore data. The Chicago dataset is the basis for this analysis. The data is air quality measurements taken over 19 years. The focus is on using the dplyr package to do the analysis. The dplyr package is part of the tidyverse in R and a suite of tools to analyze, transform, plot, and manipulate data. The base version of R does all of this; however, dplyr will work faster and cost fewer computing resources when used on big data.</description>
    </item>
    
    <item>
      <title>Using the dplyr Package in R for Simple Data Analysis</title>
      <link>/post/2018/07/04/using-the-dplyr-package-in-r-for-simple-data-analysis/</link>
      <pubDate>Wed, 04 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/07/04/using-the-dplyr-package-in-r-for-simple-data-analysis/</guid>
      <description>This article will briefly describe the dplyr package in R and the simple functions to analyze data with R for data analytics. The dplyr package in R is used for data manipulation and transformation because, typically, the data is not in a usable form. The package is useful for exploratory data analysis and a method of statistical analysis using graphical techniques. Some of the benefits are:
get insights from the data intuitivelyfind hidden trendsfind outliers and anomalous datatest assumptionshelp develop models that the data will fitThe dplyr package is used by many data scientists and analysts to manipulate data.</description>
    </item>
    
    <item>
      <title>Simple data exploration with base R functions</title>
      <link>/post/2018/07/02/simple-data-exploration-with-base-r-functions/</link>
      <pubDate>Mon, 02 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/07/02/simple-data-exploration-with-base-r-functions/</guid>
      <description>Exploring the data with base R functionsThe purpose of this post is to show the basic fucntions in R to start a data analysis project. I look at the iris dataset that comes with Rstudio shown below.This briefly covers head(), str(), attributes(), summary(), dim(), names(), indexing [], table(), and plot() functions that come with base R. Simple to use.
Load the iris datasetdata(&amp;quot;iris&amp;quot;) head()Look at the iris dataset with the head() function and lists the first five rows.</description>
    </item>
    
    <item>
      <title>Reinforcement Learning Problem</title>
      <link>/post/2018/07/01/reinforcement-learing-problem/</link>
      <pubDate>Sun, 01 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/07/01/reinforcement-learing-problem/</guid>
      <description>Reinforcement Learning - Grid World ProblemThe first section looks at the grid world concept/problem. The environment is a 3x4 grid and the goal is to move from the start xy (1,1) (called a “state”&#34;) location to the opposite corner (4,3) called the goal state. The actions are up, down, left, right. We have the rewards of +1 &amp;amp; -1. We want the agent to find the shortest sequence of actions to get from start to end (goal).</description>
    </item>
    
    <item>
      <title>K-Means - Hierarchial Cluster Analysis</title>
      <link>/post/2018/06/17/k-means-hierarchial-cluster-analysis/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/06/17/k-means-hierarchial-cluster-analysis/</guid>
      <description>K-Means AnalysisThis project will use the Wholesale customer Data Set from: https://archive.ics.uci.edu/ml/datasets/Wholesale+customers. The data has 440 orbs and 8 variables. The data has the Channel and Region as integers but they are categorical in nature with 2 channels and 3 regions. We think this may need to be taken out of the analysis but will leave them in for now. A general observation about the variables there are outliers in the 6 major variables: fresh, milk, grocery, frozen, detergents_paper, delicassen.</description>
    </item>
    
    <item>
      <title>Artificial Neural Network and Support Vector Machine Analysis</title>
      <link>/post/2018/06/10/artificial-neural-network-and-support-vector-machine-analysis/</link>
      <pubDate>Sun, 10 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/06/10/artificial-neural-network-and-support-vector-machine-analysis/</guid>
      <description>IntroductionThe data set is the mushroom set retrieved from: http://archive.ics.uci.edu/ml/datasets/Mushroom. It consists of 8124 orbs and 23 variables. The classification variable is the “type” either edible (e) or poisonous (p). The remaining 22 variables are the predictors and consist of multiple levels from 1 to 12 each. The data columns will need to be named and are coded in short for each. There are 2480 NA’s found and in one variable “sr” or stalk root.</description>
    </item>
    
    <item>
      <title>Random Forest and Decision Tree Analysis</title>
      <link>/post/2018/06/01/random-forest-and-decision-tree-analysis/</link>
      <pubDate>Fri, 01 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/06/01/random-forest-and-decision-tree-analysis/</guid>
      <description>Decision Tree and Random ForestThis analysis will utilize the data set from https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv and the purpose is to find the differences between the decision tree method and the random forest method for predicting wine quality from the 11 variables that indicate each wine’s chemical readings. The 12th variable is the quality rating given to these 1599 wines and is used as the predictor in the models. The quality has ratings from 3 to 8.</description>
    </item>
    
    <item>
      <title>Naive Bayes SMS Message Classifier</title>
      <link>/post/2018/05/27/naive-bayes-sms-message-classifier/</link>
      <pubDate>Sun, 27 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/05/27/naive-bayes-sms-message-classifier/</guid>
      <description>Naive Bayes SMS Message ClassifierThis analysis demonstrates the naive bayes classifier in determining the spam or ham status of 4837 SMS messages. The data set is retrieved from: http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection. The data needs explicit cleaning to prepare it to run through a naive bayes classifier. A training and test set is created to train and validate the predictive ability ofy the model. There are summary plots of the words found in abundance in the data.</description>
    </item>
    
    <item>
      <title>K-Nearest Neighbor (KNN) - Heart Disease Dataset</title>
      <link>/post/2018/05/20/k-nearest-neighbor-knn-heart-disease-dataset/</link>
      <pubDate>Sun, 20 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/05/20/k-nearest-neighbor-knn-heart-disease-dataset/</guid>
      <description>Introduction to K-Nearest NeighborKNN is a supervised learning algorithm and uses a training sample from the dataset, which classifies groups into different classes. It is a classifier used to predict the level of an unknown point (observation) and does this by measuring the points nearest to the unknown point. It works well in measuring the differences between multiple classes that are complex and hard to detect. KNN is considered a simple classification and regression algorithm.</description>
    </item>
    
    <item>
      <title>Data Preprocessing - Diamonds Dataset</title>
      <link>/post/2018/05/13/data-preprocessing-diamonds-dataset/</link>
      <pubDate>Sun, 13 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/05/13/data-preprocessing-diamonds-dataset/</guid>
      <description>Data PreprocessingThe following analysis is of the diamonds dataset downloaded from the tidyverse/ggplot2 Github repository. The data is in a .csv file. The purpose of the analysis is to explore the data and perform data exploration, cleaning, and preprocessing needed for modeling. Data cleaning and preprocessing involves checking for missing records, removing missing data, imputing missing data, converting categorical variables with one-hot encoding or dummy variables, scaling data, normalizing data.</description>
    </item>
    
    <item>
      <title>Real-Time Data and Smart Cities</title>
      <link>/post/2018/03/20/real-time-data-and-smart-cities/</link>
      <pubDate>Tue, 20 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/03/20/real-time-data-and-smart-cities/</guid>
      <description>Real-Time Data and Smart Cities  The Internet of Things (IoT) is a concept suggesting the number of devices connected to the Internet will continue to grow. The Internet has computers and mobile devices connected to it. The expectation is IoT will become more significant with the increasing use of sensors, actuators, and embedded devices. Currently, the Internet connects devices through wired and wireless technologies. Devices also can communicate over a network and then transfer the data to the Internet.</description>
    </item>
    
    <item>
      <title>Experimental Design</title>
      <link>/post/2017/10/01/experimental-design/</link>
      <pubDate>Sun, 01 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/10/01/experimental-design/</guid>
      <description>In the book Encyclopedia of Behavioral Medicine, Turner describes experimental design from a clinical perspective “as an experiment with a series of observations made under conditions in which the research scientist controls the influences of interest”, Turner, 2013. The randomized trial is a classic example of experimental design. The data is randomized to one of two or more experimental groups. Then the significant differences between the sets are analyzed. (Turner, 2013) The Completely Randomized Design, Randomized Block Design, and Factorial design are three experimental designs, and analysis of variance (ANOVA) will tell us whether or not there is a difference between the means of one or more independent categorical groups.</description>
    </item>
    
    <item>
      <title>About</title>
      <link>/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/about/</guid>
      <description>Welcome to my portfolio This website is a place where I present to the world the work I have been doing since early 2017. I possess a Bachelor&amp;rsquo;s in Business and a Master&amp;rsquo;s Degree in Data Science. I discovered data science in 2015 when the local news reported on the HBR article titled Data Scientist: Sexiest Job of the Century and talked about the tremendous growth and demand for professionals in the field where there were more open jobs than trained people to fill data roles.</description>
    </item>
    
  </channel>
</rss>