<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Wrangling on Bryan Schafroth Portfolio</title>
    <link>http://localhost:4321/tags/data-wrangling/</link>
    <description>Recent content in Data Wrangling on Bryan Schafroth Portfolio</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 04 Aug 2018 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:4321/tags/data-wrangling/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Hierarchical Clustering (HCA)</title>
      <link>http://localhost:4321/post/2018/08/04/hierarchical-clustering-hca/</link>
      <pubDate>Sat, 04 Aug 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/post/2018/08/04/hierarchical-clustering-hca/</guid>
      <description>&lt;div id=&#34;hierarchical-clustering&#34; class=&#34;section level3&#34;&gt;&#xD;&#xA;&lt;h3&gt;Hierarchical Clustering&lt;/h3&gt;&#xD;&#xA;&lt;p&gt;The hierarchical agglomerative clustering starts with each observation as a cluster and pairs two at a time until all clusters are merged into one single cluster. The number of clusters is not known or specified in advance. The distance between all pairs of points in the data is recorded. There is a dendrogram (upside down tree structure) that is the output of the grouping of clusters. It represents and shows how many clusters were found in the data. The hierarchical method starts at the bottom of the dendrogram and starts creating clusters. Then paired clusters that are similar are merged together. It continues until there is only one cluster. Bottom up pairing. There are four merging methods: averaging, complete, single, centroidal, and Ward’s method. Hierarchical clustering finds the nested groups of clusters and uses a distance measurement like Hamming, Manhattan, or Euclidean that is defined in the parameters of the R function. The default popular distance is the Euclidean and measures the dissimilarity between each pair of observations. The single linkage merging method looks at the shortest point in one cluster to the point in another cluster. The complete method looks at the longest point between a point in one cluster and a point in another cluster. The average linkage takes the average mean distance between each point in one cluster and each point in another cluster. It combines some of the benefits from both single and complete methods.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data Analysis - Exploratory Graphics</title>
      <link>http://localhost:4321/post/2018/07/22/data-analysis-exploratory-graphics/</link>
      <pubDate>Sun, 22 Jul 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/post/2018/07/22/data-analysis-exploratory-graphics/</guid>
      <description>&lt;div id=&#34;exploratory-graphics-in-r&#34; class=&#34;section level3&#34;&gt;&#xD;&#xA;&lt;h3&gt;Exploratory Graphics in R&lt;/h3&gt;&#xD;&#xA;&lt;p&gt;The focus of this analysis is on the ways to graph data set variables. The first section uses the EPA data set retrieved from: &lt;a href=&#34;https://github.com/jtleek/modules/blob/master/04_ExploratoryAnalysis/exploratoryGraphs/data/avgpm25.csv&#34; class=&#34;uri&#34;&gt;https://github.com/jtleek/modules/blob/master/04_ExploratoryAnalysis/exploratoryGraphs/data/avgpm25.csv&lt;/a&gt; the data was imported into a csv file and then used for this first section. Code notes for explaination.&lt;/p&gt;&#xD;&#xA;&lt;p&gt;The first part uses the RStudio base functionality to plot graphics then we use maps, lattice, and ggplot2 to compare and contrast. ggplot2 and lattice produce nice graphics quickly, while maps has state maps with county delineations among other options.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploratory Data Analysis - EPA Ozone Data</title>
      <link>http://localhost:4321/post/2018/07/14/exploratory-data-analysis-epa-ozone-data/</link>
      <pubDate>Sat, 14 Jul 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/post/2018/07/14/exploratory-data-analysis-epa-ozone-data/</guid>
      <description>&lt;div id=&#34;introduction&#34; class=&#34;section level4&#34;&gt;&#xD;&#xA;&lt;h4&gt;Introduction&lt;/h4&gt;&#xD;&#xA;&lt;p&gt;This exploratory data analysis will use the “hourly_44201_2014” data set obtained from the web site: &lt;a href=&#34;https://aqs.epa.gov/aqsweb/airdata/download_files.html#Raw&#34; class=&#34;uri&#34;&gt;https://aqs.epa.gov/aqsweb/airdata/download_files.html#Raw&lt;/a&gt; The data is “Criteria Gases” and labeled “Ozone (44201)” for this particular data set. The data is loaded into RStudio and shows 9,060,694 rows and 24 variables.&lt;/p&gt;&#xD;&#xA;&lt;p&gt;There are 24 variables in this data set. Looking through the variables, we can see the first four are coded presumably by the EPA. The Latitude, Longitude, and Datum are geo-location data. Datum NAD83 is the coordinate system for North American datum, while the WGS84 is a world coordinate system and tells that there are measurements taken presumably in another region or territory of the U.S. The “Date_Local” variable is clearly showing 365 unique dates, which cover the number of days in a year. The “Time_local” variable indicates 24 individual observations and covers each hour in a day. We see the variable measurements labeled as “Sample_Measurement” and then some more coded variables. The last variables are the “State_Name”, “County_Name”. The 53 individual names in the “State_Name” variable stand out, and this possibly coincides with the WGS84 coordinate system for U.S. States outside of the 48 States and are territories.&#xD;&#xA;In summary, we have essential geographic information, time/date information, and an Ozone measurement available in the data set. For this analysis, we can disregard the internal coding from the EPA.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data Exploration - The Chicago Dataset</title>
      <link>http://localhost:4321/post/2018/07/07/data-exploration-the-chicago-dataset/</link>
      <pubDate>Sat, 07 Jul 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/post/2018/07/07/data-exploration-the-chicago-dataset/</guid>
      <description>&lt;div id=&#34;introduction&#34; class=&#34;section level4&#34;&gt;&#xD;&#xA;&lt;h4&gt;Introduction&lt;/h4&gt;&#xD;&#xA;&lt;p&gt;This article is about using the tidyverse package in R to explore data. The Chicago dataset is the basis for this analysis. The data is air quality measurements taken over 19 years. The focus is on using the dplyr package to do the analysis. The dplyr package is part of the tidyverse in R and a suite of tools to analyze, transform, plot, and manipulate data. The base version of R does all of this; however, dplyr will work faster and cost fewer computing resources when used on big data. The functions used to explore the data are as follows:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data Preprocessing - Diamonds Dataset</title>
      <link>http://localhost:4321/post/2018/05/13/data-preprocessing-diamonds-dataset/</link>
      <pubDate>Sun, 13 May 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/post/2018/05/13/data-preprocessing-diamonds-dataset/</guid>
      <description>&lt;div id=&#34;data-preprocessing&#34; class=&#34;section level4&#34;&gt;&#xD;&#xA;&lt;h4&gt;Data Preprocessing&lt;/h4&gt;&#xD;&#xA;&lt;p&gt;The following analysis is of the diamonds dataset downloaded from the tidyverse/ggplot2 Github repository. The data is in a .csv file. The purpose of the analysis is to explore the data and perform data exploration, cleaning, and preprocessing needed for modeling. Data cleaning and preprocessing involves checking for missing records, removing missing data, imputing missing data, converting categorical variables with &lt;em&gt;one-hot encoding&lt;/em&gt; or dummy variables, scaling data, normalizing data. The majority of code is not the focus of this analysis but rest assured, and there are close to 700 lines written for the graphing presented in this article.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
